---
created: 2024-06-26T11:06:58 (UTC +08:00)
tags:
  [
    大模型开放平台,
    智谱AI开放平台,
    智谱华章,
    北京智谱华章科技有限公司,
    人工智能,
    智谱,
    模型,
    AI,
  ]
source: https://open.bigmodel.cn/dev/howuse/finetuning
author: 北京智谱华章科技有限公司
---

# 智谱 AI 开放平台 - 微调

---

## 概览

### 什么是模型微调

模型微调是指通过微调工具，加入企业独有的场景数据，对平台的基础模型进行微调。它可以帮助您快速定制出更符合您业务场景需求的专属大模型。它的优势在于对基础模型进行少量调整，满足特定的需求。相比训练新模型高效且低成本。

### 什么场景下适用微调

您可以先尝试调整提示词或者使用一些工具如函数调用 、检索功能来获得更好的效果。若您仍认为目前的基础模型及相关工具无法提供满意答案或处理复杂推理任务时，可以使用微调获得更好的效果。

微调可改善效果的典型场景：

- 需要采用特定的风格、语调
- 需要处理复杂的任务
- 需要提高输出的可靠性
- 难以通过 Prompt 说明的新任务

### 微调方式有哪些

**1. LoRA 微调**

含义：通过在模型的现有权重矩阵中添加低秩矩阵来调整模型，可以在增加少量计算负担的情况下有效调整模型。

优点：

- 只需要添加少量参数，参数效率高；
- 资源利用少且训练周期较短

**2. 全参微调**

含义：对预训练模型的所有参数进行调整获得新模型。

优点：

- 可以对模型进行全面的调整，使其更好地适应新任务；
- 在有足够数据和计算资源的情况下，更可能达到更优的性能。

### 哪些模型可以微调

`chatglm3-6b` 的 LoRA 微调训练及微调模型推理可通过购买 [开发 Pro 版权益](https://open.bigmodel.cn/tokenspropay?productIds=product-001) 进行体验； 其他模型目前仅提供给购买了云端私有化的用户进行全参微调。

- `chatglm3-6b`（LoRA 微调）
- `chatglm_12b`（购买云端私有化服务可用）
- `chatglm_32b`（购买云端私有化服务可用）
- `chatglm_66b`（购买云端私有化服务可用）
- `chatglm_130b`（购买云端私有化服务可用）

### 微调的步骤

通常情况下，完成模型微调涉及以下步骤:

1. 准备并上传训练数据
2. 训练新的微调模型
3. 部署并使用微调模型(仅当全参微调时需要手动部署）
4. 评估结果，如有需要返回到步骤 1

## 准备训练数据

微调训练数据通常由一批包含输入和期望输出的数据构成，每条训练数据由单个输入（Prompt）以及对应的期望输出组成。目前仅支持以 json 格式的文件上传训练数据。

### 数据集要求

通常情况下，提供更多的高质量训练数据，微调效果越好。反之，如果训练数据中存在问题、瑕疵，将对微调效果产生一定的负面影响。

### 更多的高质量数据

为了更好的微调模型，您需要至少提供数百条高质量的训练数据；最好由人工对数据进行过严谨的审查，以保证数据质量和微调效果。增加高质量的训练数据是提高微调效果最佳最可靠的方法。

### 根据训练目标调控数据分布

在您构造训练数据时，需注意根据真实业务场景中的训练目标，构造和调整各类细分任务场景的训练数据量分布，尽量覆盖业务场景所有可能的数据样本。如果您的训练目标是同时强化文本分类、信息提取、文本生成的效果，您需要在训练数据中分别提供适用于这几类任务的足量训练数据。

### 避免有害数据

为保证您的数据隐私性，平台不会对您的数据进行审查，请您务必检查并确保数据中不包含有害信息，包括不限于色情、暴恐违禁、政治敏感、低俗辱骂、隐私信息等有害内容。使用有害数据微调模型，可能导致微调模型容易生成有害内容，使得模型推理结果的敏感信息校验通过率变低。甚至，过于严重的有害模型将无法通过平台或有关部门的内容合规要求，将被平台强制下架。

### 数据集格式

新版数据示例（仅 `chatglm3-6b`、`chatglm3_32b`、`chatglm3_130b` 支持该版本数据，您可以通过 api 接口上传或者在模型微调训练页面进行操作）

按示例中的格式准备数据集，json 格式，每行一条，存储到文件中并调用文件管理接口上传文件：

```python
{"messages": [{"role": "system", "content": "你是一位乐于助人，知识渊博的全能AI助手。"},{"role": "user", "content": "请介绍一下AlphaGo的基本原理。"}, {"role": "assistant", "content": "AlphaGo利用深度神经网络与树搜索算法相结合,通过对弈数据进行训练,逐步提升游戏水平,能够对围棋局面进行判断并选择最佳落子位置。"}]}
{"messages": [{"role": "system", "content": "你是一位乐于助人，知识渊博的全能AI助手。"},{"role": "user", "content": "请列举一些健康饮食的重要原则。"}, {"role": "assistant", "content": "健康饮食的重要原则包括:膳食应营养均衡,合理摄入各种营养素;多吃新鲜蔬果,适量饮水;少吃糖、油、盐,忌吃过量快餐;养成规律生活作息习惯,适量运动。"}]}
{"messages": [{"role": "system", "content": "你是一位乐于助人，知识渊博的全能AI助手。"},{"role": "user", "content": "请给出一些改善睡眠质量的建议。"}, {"role": "assistant", "content": "改善睡眠质量的建议包括:保证睡眠时间,避免睡眠不足;睡前放松身心,远离刺激;养成规律作息时间,不要频繁熬夜;适量运动,但不要运动过度;睡前可以喝一杯热牛奶等温和饮料。"}]}
```

老版数据示例（适用于云端私有化用户所有模型的训练使用，但是不具备 system 功能，建议使用新数据集格式)

```python
{"input":"请介绍一下AlphaGo的基本原理。", "target":"AlphaGo利用深度神经网络与树搜索算法相结合,通过对弈数据进行训练,逐步提升游戏水平,能够对围棋局面进行判断并选择最佳落子位置。"}
{"input":"请列举一些健康饮食的重要原则。", "target":"健康饮食的重要原则包括:膳食应营养均衡,合理摄入各种营养素;多吃新鲜蔬果,适量饮水;少吃糖、油、盐,忌吃过量快餐;养成规律生活作息习惯,适量运动。"}
{"input":"请给出一些改善睡眠质量的建议。", "target":"改善睡眠质量的建议包括:保证睡眠时间,避免睡眠不足;睡前放松身心,远离刺激;养成规律作息时间,不要频繁熬夜;适量运动,但不要运动过度;睡前可以喝一杯热牛奶等温和饮料。"}
```

## 创建微调任务

如您已经按照上述说明准备好了优质的训练数据，接下来您可以开始创建微调任务，训练模型。

创建微调任务时，您可以根据需要为新模型命名，包括名称和模型编码。新模型的编码将作为 API 调用时模型编码参数值，模型编码需保证全局唯一性。如果您的模型编码与智谱 AI 官方模型命名存在冲突，我们可能需要您更换其它编码。创建微调任务后，可能需要一些时间才能完成。您的微调任务可能排在我们平台上的其他微调任务后面，训练我们的模型可能需要几小时至几天，具体取决于模型规模和数据集大小。

## 使用微调模型

模型完成微调训练后，您可以通过体验中心或 API 使用该模型。 通过 API 请求时，您可以将您命名的新模型编码作为 `model` 参数的值来传参发出请求。

调用示例

```python
from zhipuai import ZhipuAI
client = ZhipuAI(api_key="")
response = client.chat.completions.create(
model="chatglm3-6b-1001", # 填写需要调用的模型名称
messages=[
{"role": "system", "content": "你是一个人工智能助手，你叫叫chatGLM"},
{"role": "user", "content": "你好！你叫什么名字"},
],
stream=True,
)
for chunk in response:
print(chunk.choices[0].delta)
```
