## ElasticSearch 报错

### docker 启动报错

```bash
max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]
```

#### 原因

> elasticsearch 用户拥有的内存权限太小，至少需要 262144

#### 解决

-   修改 max_map_count
    ```bash
    sudo sysctl -w vm.max_map_count=262144
    ```
-   docker 中 Java 内存不低于 1G

    ```dockerfile
    -e ES_JAVA_OPTS="-Xms1g -Xmx1g"
    ```

上述方法修改之后，如果重启虚拟机将失效
需要修改 /etc/sysctl.conf

```diff
+ vm.max_map_count=262144
```

### Elastic research 报错

> elasticsearch.exceptions.ConnectionTimeout: ConnectionTimeout caused by - ReadTimeoutError(HTTPConnectionPool(host='localhost', port=9200): Read timed out. (read timeout=10))

#### 原因

默认情况下，超时值设置为 10 秒

#### 解决

如果要更改全局超时值，可以通过在创建对象时设置标志 timeout = your-time 来实现
如果您已经创建了对象而不指定超时值，则可以通过在查询中使用 request_timeout = your-time 标志来设置特定请求的超时值

```python
es.search(index="my_index",
          # doc_type="document",
          body=body,
          request_timeout=30)
```

> 413- Request too large exception

#### 原因

> You need to change the setting http.max_content_length in your elasticsearch.yml, the default value is 100 mb, you will need to add that setting in your config file with the value you want and restart your elasticsearch nodes.

`http.max_content_length` 设置默认 100m

#### 解决

减小请求体或调大并重启es

#### 参考
[The remote server returned an error: (413) Request Entity Too Large. Elasticsearch and JSON](https://stackoverflow.com/questions/58490210)


### Reference

[docker ES 启动闪退解决办法](https://blog.csdn.net/tl1242616458/article/details/105602361/)
[max virtual memory](https://www.cnblogs.com/yidiandhappy/p/7714489.html)
[elasticsearch.exceptions.ConnectionTimeout](https://blog.csdn.net/guyu1003/article/details/103584871)

**Create On 2020.11.02, Update On 2021.03.10**
